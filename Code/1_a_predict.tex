\hypertarget{load-models-and-predict-the-dataset}{%
\subsection*{Load models and predict the
dataset}\label{load-models-and-predict-the-dataset}}

\begin{lstlisting}[language=Python]
import sys
sys.path.append('../../../modules/')
import os
import gc
import base
import json
import pickle
import predict
import numpy as np
import pandas as pd
import functions_tf
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow.keras as keras
from sklearn.preprocessing import MultiLabelBinarizer
from functions_tf import ChannelAttention, SpatialAttention

mlb, elements = base.retreive_mlb_and_elements()
n_elements = len(elements)
df = pd.read_pickle(r'C:\Users\kochk\Documents\Git_Repos\Github\deep_xps\data\experimental_data_elemental.pkl')
\end{lstlisting}

\begin{lstlisting}[language=Python]
x_exp, y_exp = [df.T.values, df.columns.map(lambda x: x.split('_')[1]).values] # top layer

modeldir = r"T:\GItHub_Repos\models\1\mixcont\top_layer\models"
PLOTSDIR= r"T:\GItHub_Repos\models\1\mixcont\top_layer\models\plots_data"
KEYWORD = 'CBAM'

for root, folder, filename in os.walk(modeldir):
    for file in filename:
        if file.endswith('.h5') and KEYWORD in root and not 'vit' in file:
            MODELPATH = os.path.join(root, file)
            print(f'{MODELPATH}')
            print(file)
            if 'CBAM' in MODELPATH:
                model = keras.models.load_model(MODELPATH,
                                                custom_objects={'ChannelAttention': ChannelAttention,
                                                                           'SpatialAttention': SpatialAttention,
                                                                           'CBAM': functions_tf.CBAM})
            else:
                model = keras.models.load_model(MODELPATH)
            predictions = predict.predict_from_array_h5(x_exp, y_exp,
                                                        shape=(x_exp.shape[0], 1,1024),
                                                        model=model)
            acc = np.array([i[0] for i in predictions]).sum() / len(predictions)
            trainable_vars_N = np.sum([np.prod(v.shape) for v in model.trainable_variables])
            print(f'Number of trainable variables: {trainable_vars_N}')
            historyfile = os.path.join(PLOTSDIR, str('history_'+file.split('.')[0]+'.pkl'))
            if os.path.exists(historyfile):
                with open(historyfile, 'rb') as f:
                    history = pickle.load(f)
                print('Training set: \t', round(history['categorical_accuracy'][-1]*100, 2), '%')
                print('Valid. set: \t',round(history['val_categorical_accuracy'][-1]*100, 2), '%')
            print('Test set: \t',round(acc*100, 2), '%')
            print('\n')
            gc.collect()
            
\end{lstlisting}


\hypertarget{vit}{%
\subsection*{VIT}\label{vit}}

\begin{lstlisting}[language=Python]
x_exp, y_exp = [df.T.values, df.columns.map(lambda x: x.split('_')[0]).values] # top layer
PLOTSDIR= r"T:\GItHub_Repos\models\1\mixcont\top_layer\models\plots_data"
vitdir = r"T:\GItHub_Repos\models\1\mixcont\top_layer\models\VIT"
for file in os.listdir(vitdir):
    if 'vit' not in file or os.path.isdir(os.path.join(vitdir,file)):
        continue
    params = file.split('_')
    print(f'going for {file}')
    print(params)
    from functions_tf import VisionTransformer

    vit = VisionTransformer(
        patch_size=int(params[1]),
        hidden_size=int(params[2]),
        depth=int(params[3]),
        num_heads=int(params[4]),
        mlp_dim=int(params[5]),
        num_classes=81,
        sd_survival_probability=1,
        dropout=0.1,
        attention_dropout=0.1
    )
    vit.build(input_shape=(None, 1024, 1))
    vit.load_weights(os.path.join(vitdir,file))
    
    predictions = predict.predict_from_array(x_exp, y_exp, shape=(x_exp.shape[0], 1024,1), model=vit)
    acc = np.array([i[0] for i in predictions]).sum() / len(predictions)
    trainable_vars_N = np.sum([np.prod(v.shape) for v in vit.trainable_variables])
    print(f'Number of trainable variables: {trainable_vars_N}')
    historyfile = os.path.join(PLOTSDIR, str('history_'+file.split('.')[0][:-8]+'.pkl'))
    if os.path.exists(historyfile):
        with open(historyfile, 'rb') as f:
            history = pickle.load(f)
        print('Training set: \t', round(history['categorical_accuracy'][-1]*100, 2), '%')
        print('Valid. set: \t',round(history['val_categorical_accuracy'][-1]*100, 2), '%')
    print(f'Test set:\t {round(acc*100, 2)}%')
\end{lstlisting}

