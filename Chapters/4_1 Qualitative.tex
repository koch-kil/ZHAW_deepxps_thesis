%----------------------------------------------------------------------------------------
% SECTION 1
%----------------------------------------------------------------------------------------
\section{Qualitative elemental identification of bilayer systems}
\subsection{Elemental identification}
% model performance
The model performance for the qualitative elemental identification is shown in Table \ref{tab:acc_qual}. The categorical accuracies were computed for the individual clean and the mixcont dataset. Because experimental data can contain contamination, we generally expect the mixcont dataset to make our model more robust in that respect.
During the model development, it was obvious that we are prone to overfitting the simulated data resulting in poor performance on test data. Especially, because we do not represent the experimental spectra with enough accuracy, we must make sure to focus on the robustness of the model. Thus, the obvious approach was to choose the most simple model which was able to train effectively without overfitting and before aiming at the highest accuracy rates. The models remained unchanged for the qualitative identification for all datasets. Thus, a total of 8 models were developed for task 1 - one of each model type for each layer and the models were trained on the three datasets.

For each best performing model for each layer and dataset, the confusion matrices are shown.

\begin{table}[H]
    \centering
    \centerline{
    \begin{tabular}{c|c|c|c|c|c|c}
        Dataset & Layer & Model   & No. Parameters & Training set acc. & Validation set acc. & Test set acc.*    \\
        \hline 
        mixcont & top   & CNN     &   16.6 M       &    93.51      &    87.06       & 30.52  \\
        (n=272k)&       & CNN-DCT &  85.5 M        &    97.25      &    86.42       & 38.5      \\
                &       & CBAM    &  20.1 M        &   92.80       &    82.80       & 28.64    \\
                &       & ViT     &  25.8 K        &    75.67      &     61.97      &      61.5\\
        \hdashline
                & bot   & CNN     &                &               &                &              \\
                &       & CNN-DCT &                &               &                &              \\
                &       & CBAM    &                &               &                &             \\
                &       & ViT     &                &               &                &             \\
        \hline                                   
        clean   & top   & CNN     &                &               &                &            \\
        (n=65k)&       & CNN-DCT &                &               &                &            \\
                &       & CBAM    &                &               &                &            \\
                &       & ViT     &                &               &                &            \\
        \hdashline
                & bot   & CNN     &                &               &                &             \\
                &       & CNN-DCT &                &               &                &             \\
                &       & CBAM    &                &               &                &            \\
                &       & ViT     &                &               &                &            \\
    \end{tabular}}
    \caption{Categorical accuracies, and number of parameters of the models in respect to dataset and sample layer
    *Test Dataset n=\nelementalspectra}
    \label{tab:acc_qual}
\end{table}

From Table \ref{tab:acc_qual}, it is obvious that the performance of the bottom layer prediction is always lower than the top layer prediction. This is expected and obvious regarding the principle of XPS measurement, as electrons from the deeper layer must travel through the top layer and thus will be less intense and more influenced by scattering from interactions.

% experimental data (AG_AG etc.)
% wrong predictions -> why ? Overlap of peaks? Indirect peaks?


\subsubsection{Top layer prediction}
The best model to predict the top layer element was the Vision Transformer-Model, with an accuracy on the test dataset of 61.5 \%. Figure \ref{fig:top_best_loss} shows the categorical crossentropy loss and categorical accuracy for the training (blue) and the validation (orange) datasets respectively. According to the plots, we start overfitting after 25 epochs. In the confusion matrix, we can see that in the test dataset, Dysprosium (Dy) has been wrongly predicted as Carbon 4 times, which are the most failures of the falsely predicted elements. An approach would be to plot the attention of the model on Dysprosium and Carbon spectrum data to investigate the reason behind.

\begin{figure}
    \centering
    \includegraphics{Figures/attention_map_dy.png}
    \caption{Caption}
    \label{att:dy}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Figures/top_best_loss_acc_vit_4_32_3_4_64.png}
    \caption{Categorical crossentropy loss and crossentropy accuracy for the ViT model training on top-layer training data-labels}
    \label{fig:top_best_loss}
\end{figure}

\begin{center}
\begin{figure}[H]
        \centerline{\includegraphics[width=1.4\textwidth]{Figures/best_task_1_model_CM.png}}
    \centering
    \caption{Confusion Matrix of Test-Data for best Top-Layer prediction}
    \label{cm_cnn_1l}
\end{figure}
\end{center}



\subsubsection{Bot layer prediction}
From the experimental data, $\nelementalspectra$ elemental spectra were used as the test dataset. Because survey scans of buried layers are rare, we considered pure elemental spectra to be composed of a buried layer of the pure element respectively.

\subsection{Depth profile determination of native oxides and elements}
% As there's almost no test data this is experimental
Depth profiling or determination of overlayer thickness is often conducted in scientific experiments. However, data is usually not publicly available - and if - it does often not include survey spectra. This is because these measures are usually done with ion-sputtering profiling or angle-resolved measurements and as these experiments are time-consuming, only the regions of interests (where the peaks are expected depending on the sample) are scanned.
As depth profiling data is not readily available from public databases, the datasets obtained internally as explained in chapter \ref{exp_depth}, were used to evaluate the model on experimental data.
% model performance


\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
        Dataset & Model   & No. Parameters & Training Dataset    & Validation Dataset    \\
        \hline
 mixcont+oxides& CNN     &                &                       &                         \\
               & CNN-DCT &                &                       &                         \\
               & CBAM    &                &                       &                         \\
               & ViT     &                &                       &                         \\

    \end{tabular}
    \caption{ and number of Parameters of the models in respect to dataset and layer}
    \label{tab:acc_depth}
\end{table}

% experimental data (AG_AG etc.)


