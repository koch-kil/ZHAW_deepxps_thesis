%----------------------------------------------------------------------------------------
% SECTION 1
%----------------------------------------------------------------------------------------
\section{Qualitative elemental identification of bilayer systems}
\subsection{Elemental identification}
% model performance
The model performance for the qualitative elemental identification is shown in Table \ref{tab:acc_qual}. The categorical accuracies were computed for the individual clean and the mixcont dataset. Because experimental data can contain contamination, we generally expect the mixcont dataset to make our model more robust in that respect.
During the model development, it was obvious that we are prone to overfitting the simulated data resulting in poor performance on test data. Especially, because we do not represent the experimental spectra with enough accuracy, we must make sure to focus on the robustness of the model. Thus, the obvious approach was to choose the most simple model which was able to train effectively without overfitting and before aiming at the highest accuracy rates. The models remained unchanged for the qualitative identification for all datasets. Thus, a total of 8 models were developed for task 1 - one of each model type for each layer and the models were trained on the three datasets. For each best performing model for each layer and dataset, the confusion matrices are shown.

\begin{table}[H]
    \centering
    \centerline{
    \begin{tabular}{c|c|c|c|c|c|c}
        Dataset & Layer & Model   & No. Parameters & Training set & Validation set & Test set*    \\
        \hline 
        mixcont & top   & CNN     &  8.2 M        &    92.37      &    86.68 & 27.91       \\
        (n=272k)&       & CNN-DCT &  12.3 M        &   91.34        &    86.58       & 14.42           \\
                &       & CBAM    &  20.1 M        &  92.80       &    82.80       & 28.64          \\
                &       & ViT     &  35.8 K        &    79.92     &    82.69       & \textbf{52.56}  \\
        \hdashline
                & bot   & CNN     &   82.1 M       &\textbf{89.05}&   \textbf{79.64}    &     45.12      \\
                &       & CNN-DCT &   12.3 M       &    85.39      &    79.39       &   50.23       \\
                &       & CBAM    &   20.1 M        &    86.65     &    70.96     &       27.44    \\
                &       & ViT     &   35.8 K      &     61.65     &      68.35    &  \textbf{57.21} \\
        \hline                                   
        clean   & top   & CNN     &   8.2 M        &               &                &            \\
        (n=65k)&       & CNN-DCT &    12.3 M      &               &                &            \\
                &       & CBAM    &   20.1 M       &               &                &            \\
                &       & ViT     &   35.8 K       &               &                &            \\
        \hdashline
                & bot   & CNN     &   8.2 M         &               &                &             \\
                &       & CNN-DCT &   12.3 M        &               &                &             \\
                &       & CBAM    &   20.1 M        &               &                &            \\
                &       & ViT     &   35.8 K        &               &                &            \\
    \end{tabular}}
    \caption{Categorical accuracies, and number of parameters of the models in respect to dataset and sample layer
    *Test Dataset n=\nelementalspectra}
    \label{tab:acc_qual}
\end{table}


\subsubsection{Top layer prediction}
The best model to predict the top layer element was the Vision Transformer-Model, with an accuracy on the test dataset of 52.56 \%. Figure \ref{fig:top_best_loss} shows the categorical crossentropy loss and categorical accuracy for the training (blue) and the validation (orange) datasets respectively. In the confusion matrix, we can see that in the test dataset, Iron (Fe) has been wrongly predicted as Lithium (Li) a total of 4 times, which are the most failures of any wrongly predicted elements. An approach would be to plot the attention of the model on Lithium and Iron spectrum data to investigate the reason behind. However, as shown in Figures \ref{att:Fe} and \ref{att:Li}, they overlap at a binding energy of 55 eV. This is a known overlap of the Li 1s and Fe 3p peaks. However, as the attention does not focus on this part for the Iron spectrum, it is not obvious why this faulty prediction was done. It suggests that the model lacks complexity as both cases overlap in the feature space. As the model only has 25.8k trainable parameters, this is very much possible. 


\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{Figures/best_task_1_model_loss.png}
    \caption{Categorical crossentropy loss and crossentropy accuracy for the ViT model training on top-layer training data-labels}
    \label{fig:top_best_loss}
\end{figure}

\begin{figure}[H]

    \begin{subfigure}[b]{1\textwidth}
            \includegraphics[width=\textwidth]{Figures/attention_map_Li.png}
            \caption{Attention map (blue) for the Lithium spectrum (red) prediction}
            \label{att:Li}
    \end{subfigure}
    \begin{subfigure}[b]{1\textwidth}
            \includegraphics[width=\textwidth]{Figures/attention_map_Fe.png}
            \caption{Attention map (blue) for the experimental Iron spectrum (red) prediction}
            \label{att:Fe}
    \end{subfigure}
    
    \begin{subfigure}[b]{1\textwidth}
            \includegraphics[width=\textwidth]{Figures/attention_map_Fe_Training.png}
            \caption{Attention map (blue) for the simulated Iron spectrum (red) prediction}
            \label{att:FeSim}
    \end{subfigure}
\caption{Attention maps of false top layer predictions}
\end{figure}


\begin{center}
\begin{figure}[H]
        \centerline{\includegraphics[width=1.4\textwidth]{Figures/best_task_1_model_CM.png}}
    \centering
    \caption{Confusion natrix of test dataset for best top-layer prediction}
    \label{cm_cnn_1l}
\end{figure}
\end{center}



\subsubsection{Bot layer prediction}


From the experimental data, the same test dataset was used as for the top-layer prediction. Because survey scans of buried layers are rare, we considered pure elemental spectra to be composed of a buried layer of the pure element respectively.
From Table \ref{tab:acc_qual}, we can see that the performance of the bottom layer prediction is not always lower than the top layer prediction. However, we would expect a lower accuracy for the bottom layer, due to the principle of XPS measurement, as electrons from the deeper layer must travel through the top layer and thus will be less intense and more influenced by scattering from interactions. Anyway, as we consider experimental data from pure elements as a two-layer system in our test-set, it could also be that the simulated spectra from buried pure elements actually resembles ground truth more accurately. However, the most probable explanation is that the early stopping stopped the model from overfitting because it was harder to train the bot-layer labels due to the previously mentioned scattering effects.




\subsection{Depth profile determination of native oxides and elements}

% As there's almost no test data this is experimental
Depth profiling or determination of overlayer thickness is often conducted in scientific experiments. However, data is usually not publicly available - and if - it does often not include survey spectra. This is because these measures are usually done with ion-sputtering profiling or angle-resolved measurements and as these experiments are time-consuming, only the regions of interests (where the peaks are expected depending on the sample) are scanned.
As depth profiling data is not readily available from public databases, the datasets obtained internally as explained in chapter \ref{exp_depth}, were used to evaluate the model on experimental data.
% model performance

\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c}
        Dataset & Model   & No. Parameters & Training Dataset    & Validation Dataset    \\
        \hline
 mixcont+oxides& CNN     &                &                       &                         \\
               & CNN-DCT &                &                       &                         \\
               & CBAM    &                &                       &                         \\
               & ViT     &                &                       &                         \\

    \end{tabular}
    \caption{ and number of Parameters of the models in respect to dataset and layer}
    \label{tab:acc_depth}
\end{table}

The test data contained seven spectra with the structure explained in \ref{exp_depth}. Each spectrum is evaluated with each model and the results are shown in Table 


\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|c}
        Model  &    \multicolumn{3}{|c|}{Al-Oxide}     & \multicolumn{4}{c}{Cu/Pd}            \\
        \hline
Ground truth   &       2   &   1.5   &  0   & 20   & 10    & 1     & 0                               \\
\hline
  CNN          &           &        &       &      &       &       &                                     \\
CNN-DCT        &           &        &       &      &       &       &                                     \\
CBAM           &           &        &       &      &       &       &                                     \\
ViT            &           &        &       &      &       &       &                                     \\

    \end{tabular}
    \caption{Depth predictions and ground truth in nanometers for the seven test data spectra}
    \label{tab:acc_depth}
\end{table}
