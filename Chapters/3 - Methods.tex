% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%----------------------------------------------------------------------------------------
% CHAPTER TEMPLATE
%----------------------------------------------------------------------------------------
\chapter{Methods} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\input{Chapters/3_1 Train_Data}


\input{Chapters/3_2 Test_Data}


\section{Model architectures \& training}
In this section, the models used in our research are explained.
%Models were designed with two output-layers which correspond to the respective layers of our modelled sample. 
The training dataset was split into training and validation datasets. A first model was built respectively for each of the tasks listed in the \nameref{Chapter1} for the four models: CNN, CNN-DCT, CBAM, ViT. The model 

\subsection{Loss functions and hyperparameters}
The tasks presented in Chapter \ref{Chapter1} are considered and assigned a task type.
% multi-class classification problem (exclusive)
The first task is a multiclass classification problem, which means we need to find one corresponding element for the two layers, where the elements are exclusive (only one is true).
% multi-label classification (nonexclusive)

\subsection{CNN}
% explain the structure
The CNN model used is based on the standard architecture with two convolutional blocks. The first blocks consist of four consecutive convolutional layers with increasing kernel sizes (1, 3, 7, 21) to extract more and more general features, while the second block has kernel sizes (3, 5, 21, 37). Each block uses 64 filters, the ReLU activation function, starts with a batch-normalization layer and ends with a max-pooling layer. Finally, the model has two dense layers with 1024 nodes connected through a dropout-layer (p = 0.2) and subsequent batch-normalization. Finally, a the softmax function is applied to the dense output layer with 81 nodes corresponding to the elements.

% show the structure

The corresponding code can be found in the Appendix \ref{AppendixB}


\subsection{CNN-DCT}
% explain the structure
The discrete cosine transform (DCT) of a natural signal decomposes it into the frequency domain, where the intensities correspond to cosine waves in our original spectrum. This induces sparsity into our data, which means that only a few components are responsible for most of the signal. An example of a DCT-transformed XPS-signal is shown in Figure \ref{fig:dct}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Figures/dct.png}
    \caption{Original simulated XPS-signal (a) and a sparse representation, the discrete-cosine transformed XPS-signal (b)}
    \label{fig:dct}
\end{figure}
% show the structure


\subsection{ViT}
The vision transformer model used for the 1D-Spectra was inspired from Yoni Gottesmans blogpost \cite{noauthor_interpretable_2023}. It takes the published 2D-ViT model  as a basis and is adapted to work with one-dimensional inputs.
The model was adapted to fit the spectral input data with 1024 data points. Further, a patch-size of 8 data-points and the number of heads chosen was 16.
The Multilayer Perceptron (MLP) is of size 512 and the model consists of two Transformer blocks.
% explain the structure

% show the structure



\subsection{CBAM}
The code for the convolutional block attention module base blocks was found on Github and modified to fit our 1D-data \cite{mazzia__2023}.
% explain the structure
The blocks were then included in a convolutional model such that the CBAM blocks can learn on the extracted features with its attention-modules.

% show the structure


\section{Model evaluation}

To evaluate the models' performance and training process, the loss and accuracy was obtained and plotted. Furthermore, the test data obtained as described in Chapter \ref{test_data} was predicted and visualized in a confusion matrix to be found in Appendix \ref{AppendixB}.
% table showing the accuracies for the test data
%The accuracies for the test dataset are shown for the respective datasets and models used in \ref{}.