% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%----------------------------------------------------------------------------------------
% CHAPTER TEMPLATE
%----------------------------------------------------------------------------------------


\chapter{Methods} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\input{Chapters/3_1 Train_Data}


\input{Chapters/3_2 Test_Data}


\section{Model architectures}
In this section, the models used in our research are explained. Models were designed with two output-layers which correspond to the respective layers of our modelled sample. It should be noted that - due to the small amount of information from the bottom layer - we expect a lower performance compared to the top layer.

\subsection{CNN}
% explain the structure
The CNN model used is based on the standard architecture with two convolutional blocks. The blocks consist of four consecutive convolutional layers with increasing kernel sizes (1, 3, 7, 21) to extract more and more general features. Each block starts with a batch-normalization layer and ends with a max-pooling layer. Finally, the model has two dense layers connected through a dropout-layer (p = 0.5) and subsequent batch-normalization.

% show the structure

The corresponding code can be found in the Appendix \ref{AppendixB}

\subsection{CNN-DCT}
% explain the structure
The discrete cosine transform (DCT) of a natural signal decomposes it into the frequency domain, where the intensities correspond to cosine waves in our original spectrum. This induces sparsity into our data, which means that only a few components are responsible for most of the signal. An example of a DCT-transformed XPS-signal is shown in \ref{fig:dct}.

\begin{figure}[H]
    \centering
    \includegraphics{Figures/dct.png}
    \caption{Caption}
    \label{fig:dct}
\end{figure}
% show the structure

\subsection{ViT}
The visual attention model used for the 1D-Spectra was inspired from Yoni Gottesmans blogpost \cite{noauthor_interpretable_2023}. It takes the published 2D-ViT model  as a basis and is adapted to work with one-dimensional inputs.
The model was adapted to fit the spectral input data with 1024 data points. Further, a patch-size of 20 data-points and a head of 6 was chosen.
% explain the structure

% show the structure


\subsection{ViA}
% explain the structure


% show the structure


\section{Model evaluation}

To evaluate the models' performance and training process, the loss and accuracy was obtained and plotted. Furthermore, the test data obtained as described in \ref{test_data} was predicted and visualized in a confusion matrix to be found in Appendix \ref{ApendixB}.