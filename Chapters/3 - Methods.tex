% Indicate the main file. Must go at the beginning of the file.
% !TEX root = ../main.tex

%----------------------------------------------------------------------------------------
% CHAPTER TEMPLATE
%----------------------------------------------------------------------------------------
\chapter{Methods} % Main chapter title

\label{Chapter3} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\input{Chapters/3_1 Train_Data}


\input{Chapters/3_2 Test_Data}


\section{Classification types, model architectures \& training}
In this section, the classification types from our tasks, the models used and the training procedure used in this work are explained.
The tasks presented in the \nameref{Chapter1} are considered and assigned a task type.
% multi-class classification problem (exclusive)
The first task is a multi-class classification problem, which means we need to find one corresponding element for one of the two layers, where the elements are exclusive (only one is true). Task two seeks to infer the depth of the layer in one number between 0 and 1. In our two-layer system, this is a regression problem, since there is a regressive behaviour between the input spectrum and the overlayer thickness. The third task is a multi-label classification problem, as each input can be assigned multiple true labels. Additionally, it is a special type of multi-label classification, as the labels are not exclusively 0 or 1 but can take any value in between. This is because the proportional quantity of the respective elements is encoded in the label.
% multi-label classification (nonexclusive)
%Models were designed with two output-layers which correspond to the respective layers of our modelled sample. 

To start the modelling procedure, the training dataset was split into training and validation datasets with a ration of 80:20. A first model was built respectively for each of the tasks listed in the \nameref{Chapter1} for the four models: CNN, CNN-DCT, CBAM, ViT. The models architectures were then changed such that it efficiently trains on the respective training dataset. This was evaluated by comparing training loss and accuracy. If the training data loss decreases and its accuracy increases, we successfully train the model.
The validation loss is then used to tune the hyperparameters and add normalization to the model until the model showed convex training behaviour and no overfitting. Lastly, the models were trained with an early stopping callback function which monitored the model loss to stop the training when there was no improvment >0.002 for five consecutive epochs.

\subsection{Loss functions and hyperparameters}

\subsection{CNN}
% explain the structure
The CNN model used is based on the standard architecture with two convolutional blocks. The first blocks consist of four consecutive convolutional layers with increasing kernel sizes (TODO) to extract more and more general features, while the second block has kernel sizes (TODO). Each block uses 16 filters, the ELU activation function, starts with a batch-normalization layer and ends with a max-pooling layer.
As these two blocks are used as a feature-extraction tool, the features are then flattened to one dimension before being connected through a dropout-layer (p = 0.4) and subsequent batch-normalization. Finally, the softmax function is applied to the dense output layer with 81 nodes corresponding to the elements.

During the development of an adequate CNN-model, batch-normalization seemed to have a big impact on the model 
% show the structure

The corresponding code can be found in the Appendix \ref{AppendixB}


\subsection{CNN-DCT}
% explain the structure
The discrete cosine transform (DCT) of a natural signal decomposes it into the frequency domain, where the intensities correspond to cosine waves in our original spectrum. This transforms out signal into a sparse representation, which means that the signal is composed of only a few components. An example of a DCT-transformed XPS-signal is shown in Figure \ref{fig:dct}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{Figures/dct.png}
    \caption{Original simulated XPS-signal (a) and a sparse representation, the discrete-cosine transformed XPS-signal (b)}
    \label{fig:dct}
\end{figure}

% show the structure


\subsection{ViT}
The vision transformer model used for the 1D-Spectra was inspired from Yoni Gottesmans blogpost \cite{noauthor_interpretable_2023}. It takes the published 2D-ViT model  as a basis and is adapted to work with one-dimensional inputs.
The model was adapted to fit the spectral input data with 1024 data points. Further, a patch-size of 8 data-points and the number of heads chosen was 16.
The Multilayer Perceptron (MLP) is of size 512 and the model consists of two Transformer blocks.
% explain the structure

% show the structure



\subsection{CBAM}
The code for the convolutional block attention module base blocks was found on Github and modified to fit our 1D-data \cite{mazzia__2023}.
% explain the structure
The blocks were then included in a convolutional model such that the CBAM blocks can learn on the extracted features with its attention-modules.

% show the structure


\section{Model evaluation}

When a model should be evaluated, the specific computation to obtain its performance must be adapted to its type, such as multi-class classification. 
To evaluate the models' performance and training process, the loss and accuracy was obtained and plotted. Furthermore, the test data obtained as described in Chapter \ref{test_data} was predicted and visualized in a confusion matrix to be found in Appendix \ref{AppendixB}.
% table showing the accuracies for the test data
%The accuracies for the test dataset are shown for the respective datasets and models used in \ref{}.